{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_excel('annotation_data_train_method.xlsx', sheet_name='a1')\n",
    "df_2 = pd.read_excel('annotation_data_train_method.xlsx', sheet_name='a2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>used</th>\n",
       "      <th>used_Felix</th>\n",
       "      <th>Anmerkung</th>\n",
       "      <th>ner</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pre_sentence</th>\n",
       "      <th>post_sentence</th>\n",
       "      <th>section_name</th>\n",
       "      <th>section_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30875.0</td>\n",
       "      <td>10203151008a20b32ce089f7f9d580005c2426cf</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>convolutional layer activations</td>\n",
       "      <td>In particular for image retrieval , Babenko et...</td>\n",
       "      <td>Using CNN layer activations as off - the - she...</td>\n",
       "      <td>Generalization to other tasks is attained by C...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>97801.0</td>\n",
       "      <td>4087ebc37a1650dbb5d8205af0850bee74f3784b</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>weight initialization</td>\n",
       "      <td>A poor weight initialization may take longer t...</td>\n",
       "      <td>Optimal parameter initialization remains a cru...</td>\n",
       "      <td>Here , we propose a method of weight re - init...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>54406.0</td>\n",
       "      <td>220a0b46840a2a1421c62d3d343397ab087a3f17</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spatio - temporal filters</td>\n",
       "      <td>Spatio - temporal filters .</td>\n",
       "      <td>Of course spatial pyramids are widely used in ...</td>\n",
       "      <td>Burt and Adelson lay out the theory of spatio ...</td>\n",
       "      <td>Related Work</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>103733.0</td>\n",
       "      <td>435259c5f3cffd75ef837a8e638cc8f6244e25c4</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sliding - window strategy</td>\n",
       "      <td>A naive approach follows a sliding - window st...</td>\n",
       "      <td>Originally designed for image recognition and ...</td>\n",
       "      <td>As explained before , this technique presents ...</td>\n",
       "      <td>Methods</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17186.0</td>\n",
       "      <td>0a053f55804eee01f3c8b4138a1d3364d5bc45ac</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural LP</td>\n",
       "      <td>IRN and Neural LP explore multi - step relatio...</td>\n",
       "      <td>Hence , recent works have proposed approaches ...</td>\n",
       "      <td>Compared to RL - based approaches , it is hard...</td>\n",
       "      <td>Knowledge Base Completion</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>38388.0</td>\n",
       "      <td>15cc54ed7b1582b2efd71bedf28b23634d82991b</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MMD - rep - b</td>\n",
       "      <td>[ reference ] shows that : When PICO was used ...</td>\n",
       "      <td>Fig .</td>\n",
       "      <td>For hinge and MMD - rbf , higher may result in...</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>27104.0</td>\n",
       "      <td>0ee850dd6640a96531ac5ad21da5438db04d8b3c</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep neural ranking models</td>\n",
       "      <td>In particular , we use classic unsupervised IR...</td>\n",
       "      <td>To overcome this issue , in this paper , we pr...</td>\n",
       "      <td>Weak supervision here refers to a learning app...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>25448.0</td>\n",
       "      <td>0d5fa5be4bfe085de8f88dbee1c3b2a6e5ab9ee2</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gradual feature fusion steps</td>\n",
       "      <td>With proposed gradual feature fusion steps and...</td>\n",
       "      <td>[ reference ] and [ reference ] show the visua...</td>\n",
       "      <td>Intriguingly , output of the ‘ sub4 ’ branch c...</td>\n",
       "      <td>Visual Improvement</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>12675.0</td>\n",
       "      <td>071b16f25117fb6133480c6259227d54fc2a5ea0</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>long short - term memory ( LSTM ) unit</td>\n",
       "      <td>This gated unit is similar to a long short - t...</td>\n",
       "      <td>The gated hidden unit is an alternative to the...</td>\n",
       "      <td>This is made possible by having computation pa...</td>\n",
       "      <td>Recurrent Neural Network</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>72738.0</td>\n",
       "      <td>2e10643c3759f97b673ff8c297778c0b6c20032b</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>distributed word representation</td>\n",
       "      <td>Comparing with traditional models , this sugge...</td>\n",
       "      <td>One of the most obvious facts one could observ...</td>\n",
       "      <td>However , our experiments does not speak for a...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>107712.0</td>\n",
       "      <td>46018a894d533813d67322827ca51f78aed6d59e</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic model</td>\n",
       "      <td>The segmentation results on two subjects from ...</td>\n",
       "      <td>However , we can study the impact these featur...</td>\n",
       "      <td>As shown in the figure , the two - phase train...</td>\n",
       "      <td>The TwoPathCNN architecture</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4393.0</td>\n",
       "      <td>027f9695189355d18ec6be8e48f3d23ea25db35d</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete distribution</td>\n",
       "      <td>Gumbel - Softmax ( Jang , Gu , and Poole 2017 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Since it approximates one - hot vectors sample...</td>\n",
       "      <td>Gumbel - Softmax</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13557.0</td>\n",
       "      <td>07c4fc48ad7b7d1a417b0bb72d0ae2d4efc5aa83</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>convolution window size</td>\n",
       "      <td>subsection : Filter dilation and convolution w...</td>\n",
       "      <td>In particular , in our experiments we always a...</td>\n",
       "      <td>Filter dilation , as introduced in , is a tech...</td>\n",
       "      <td>Filter dilation and convolution window size</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5922.0</td>\n",
       "      <td>03184ac97ebf0724c45a29ab49f2a8ce59ac2de3</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attribute representations</td>\n",
       "      <td>Attribute representations are defined as a vec...</td>\n",
       "      <td>Discrete vs Continuous Attributes .</td>\n",
       "      <td>These vectors ( 85 - dim for AWA , 312 - dim f...</td>\n",
       "      <td>Experimental Results</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>34427.0</td>\n",
       "      <td>12f008bea798a05ebfa2864ec026999cb375bcd9</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>AS Reader</td>\n",
       "      <td>Lastly , on CBT - CN the GA Reader with the qe...</td>\n",
       "      <td>For CBT - NE , GA Reader with the qe - comm fe...</td>\n",
       "      <td>For each of the 4 datasets on which GA achieve...</td>\n",
       "      <td>Performance Comparison</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>02a5b7a41ffa8518eb3b7cae9914a2bd2bbc886b</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Min - max strategy</td>\n",
       "      <td>To initialise SiamMask , we extract the axis -...</td>\n",
       "      <td>For each measure C ∈ { J , F } , three statist...</td>\n",
       "      <td>Similarly to most VOS methods , in case of mul...</td>\n",
       "      <td>Evaluation for semi - supervised VOS</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>61151.0</td>\n",
       "      <td>25c108a56e4cb757b62911639a40e9caf07f1b4f</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shallow version</td>\n",
       "      <td>The structure of our model is a shallow versio...</td>\n",
       "      <td>All faces are labelled with bounding boxes and...</td>\n",
       "      <td>We use this model in scale - forecast network ...</td>\n",
       "      <td>Setup and Implementation Details</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>27028.0</td>\n",
       "      <td>0ecd4fdce541317b38124967b5c2a259d8f43c91</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Markovian</td>\n",
       "      <td>The RAM is therefore a relatively compact repr...</td>\n",
       "      <td>The Atari 2600 has only bits of random access ...</td>\n",
       "      <td>The purpose of our RAM - based agent is to inv...</td>\n",
       "      <td>RAM - based Feature Generation</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>79855.0</td>\n",
       "      <td>33a8d0a35390fde736744d4a0dd20dff7961c777</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dropout technique</td>\n",
       "      <td>In between intermediate layers , we use batch ...</td>\n",
       "      <td>Output of layer is then passed to two fully co...</td>\n",
       "      <td>We set depending upon the dataset size ( towar...</td>\n",
       "      <td>Experiment and Results</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>52443.0</td>\n",
       "      <td>207e0ac5301a3c79af862951b70632ed650f74f7</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning based model</td>\n",
       "      <td>In addition , deep learning based model is als...</td>\n",
       "      <td>Note that XQDA can be considered as hybrid bet...</td>\n",
       "      <td>For fair comparison , whenever possible ( i.e....</td>\n",
       "      <td>Fully Supervised Learning Results</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>46567.0</td>\n",
       "      <td>1bc072002d97808340b312b69427baf2dc9fcb8e</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feature transformation methods</td>\n",
       "      <td>To get our DNNs efficiently work , we propose ...</td>\n",
       "      <td>To tackle the issue , we propose two novel mod...</td>\n",
       "      <td>denoising auto - encoders ( DAEs ) .</td>\n",
       "      <td>Deep Learning over Multi - field Categorical Data</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>102438.0</td>\n",
       "      <td>42f20d37f4eba56284a941d5f9f58609ee650de0</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assumed kernel</td>\n",
       "      <td>On the other hand , when the assumed kernel is...</td>\n",
       "      <td>Most of SISR methods actually favor for such c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blur kernel .</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>33378.0</td>\n",
       "      <td>1109b663453e78a59e4f66446d71720ac58cec25</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>localization approach</td>\n",
       "      <td>Our localization approach won the 2013 ILSVRC ...</td>\n",
       "      <td>The scheme we propose involves substantial mod...</td>\n",
       "      <td>The detection model was among the top performe...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>98917.0</td>\n",
       "      <td>40eb1e54cb5382dfd3b7efd16dc7df826262ea52</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>box estimation network</td>\n",
       "      <td>The center residual predicted by the box estim...</td>\n",
       "      <td>We take a “ residual ” approach for box center...</td>\n",
       "      <td>[ reference ] ) .</td>\n",
       "      <td>Amodal 3D Box Estimation PointNet</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>104535.0</td>\n",
       "      <td>4402c6c8445f17f4161e0f64573b7e28df1ca180</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu function</td>\n",
       "      <td>Compared with the sigmoidal family , relu func...</td>\n",
       "      <td>x ) .</td>\n",
       "      <td>Figure 5 compares these activation functions o...</td>\n",
       "      <td>1 ) Embedding Layer :</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>17068.0</td>\n",
       "      <td>0a053f55804eee01f3c8b4138a1d3364d5bc45ac</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>embedding - based models</td>\n",
       "      <td>We compare against RL - based methods , embedd...</td>\n",
       "      <td>We use HITS@1 , 3 and mean reciprocal rank ( M...</td>\n",
       "      <td>For all the baseline methods , we used the imp...</td>\n",
       "      <td>Knowledge Base Completion</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>72024.0</td>\n",
       "      <td>2dad7e558a1e2982d0d42042021f4cde4af04abf</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dilated models</td>\n",
       "      <td>Also , the dilated models outperform their reg...</td>\n",
       "      <td>To the best of our knowledge , the dilated GRU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language modeling</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>72901.0</td>\n",
       "      <td>2e4c06dd00c4c09ad5ac6be883cc66c19d88ea79</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>augmented MBCE loss</td>\n",
       "      <td>In this work , we enforce both inputs to be in...</td>\n",
       "      <td>The motivation behind this design is to mainta...</td>\n",
       "      <td>At inference time , we use the reconstructed o...</td>\n",
       "      <td>Link Prediction</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29656.0</td>\n",
       "      <td>0fbd17a4f791e04bbf8f240f7c48c178900e30a6</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smooth loss</td>\n",
       "      <td>We used Focal loss with and smooth loss for cl...</td>\n",
       "      <td>We optimized subnet with Adam starting from le...</td>\n",
       "      <td>We obtained final proposals using NMS with a t...</td>\n",
       "      <td>Person Detection Subnet :</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>7767.0</td>\n",
       "      <td>051b3763c2ad4e4271db712b0e9a4cfe298d05db</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f - warp layer</td>\n",
       "      <td>Unlike Spatial Transformer , f - warp layer is...</td>\n",
       "      <td>Our network uses the proposed f - warp layer t...</td>\n",
       "      <td>While transformation in FlowNet2 and SPyNet is...</td>\n",
       "      <td>Related Work</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>18807.0</td>\n",
       "      <td>0a3a003457f5d7758a42a0e4b7278b39a86ed0bd</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meta - batch strategy</td>\n",
       "      <td>Using our HT meta - batch strategy , hard task...</td>\n",
       "      <td>The size of meta - batch is set to ( tasks ) d...</td>\n",
       "      <td>The number of hard task is selected for differ...</td>\n",
       "      <td>Implementation details</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>93702.0</td>\n",
       "      <td>3d734edc41c13fb4da2c3709e8255b004d083962</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTI - SCALE INFORMATION LEARNING NETWORK STR...</td>\n",
       "      <td>section : PROPOSED MULTI - SCALE INFORMATION L...</td>\n",
       "      <td>Furthermore , the output of the dilated convol...</td>\n",
       "      <td>The configuration of our proposed single image...</td>\n",
       "      <td>PROPOSED MULTI - SCALE INFORMATION LEARNING NE...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>99486.0</td>\n",
       "      <td>41232a69c0f8d4b993e6c6e00b16c223442c962f</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sequence - to - sequence</td>\n",
       "      <td>The dual - attention sequence - to - sequence ...</td>\n",
       "      <td>To avoid generating fake facts in a summary , ...</td>\n",
       "      <td>Experiments on the Gigaword benchmark dataset ...</td>\n",
       "      <td>Faithful to the Original : Fact Aware Neural A...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>103516.0</td>\n",
       "      <td>434bf475addfb580707208618f99c8be0c55cf95</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse feature representation</td>\n",
       "      <td>This helps creating a sparse feature represent...</td>\n",
       "      <td>When initializing the weights uniformly , half...</td>\n",
       "      <td>Another positive aspect is the relatively chea...</td>\n",
       "      <td>Rectified Linear Unit</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>71595.0</td>\n",
       "      <td>2d876ed1dd2c58058d7197b734a8e4d349b8f231</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cuDNN library ’s RNN primitives</td>\n",
       "      <td>It is also important to note that the cuDNN li...</td>\n",
       "      <td>Note that the softmax , over a vocabulary size...</td>\n",
       "      <td>That is , running an LSTM that uses a state - ...</td>\n",
       "      <td>Language Modeling</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>86649.0</td>\n",
       "      <td>36c3972569a6949ecca90bfa6f8e99883e092845</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detectron models</td>\n",
       "      <td>Second , we choose models trained with differe...</td>\n",
       "      <td>As can be seen from Fig [ reference ] , the pe...</td>\n",
       "      <td>As can be seen , this ensembling strategy is m...</td>\n",
       "      <td>Model Ensembling</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>53325.0</td>\n",
       "      <td>20cc4bfdb648fd7947c71252589fc867d4d16933</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>To qualitatively study the improvement in loca...</td>\n",
       "      <td>Change in Class - Activation Mapping :</td>\n",
       "      <td>As shown in Figure 3 , PC models provide tight...</td>\n",
       "      <td>Improvement in Localization Ability</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>35823.0</td>\n",
       "      <td>143a3186c368544ded00a444be33153420baa254</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pretraining baseline</td>\n",
       "      <td>The pretraining baseline in the main text trai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To evaluate the model , as with MAML , we fine...</td>\n",
       "      <td>C.1 . Multi - task baselines</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>28073.0</td>\n",
       "      <td>0f0cab9235bbf185acdd4f9713fd111ca50effca</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogEig layer</td>\n",
       "      <td>The final LogEig layer endows elements in Riem...</td>\n",
       "      <td>As discussed earlier , SPD matrices lie on Rie...</td>\n",
       "      <td>If be input matrix , be output matrix , the Lo...</td>\n",
       "      <td>Log Eigenvalue Layer ( LogEig )</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>15174.0</td>\n",
       "      <td>0899bb0f3d5425c88b358638bb8556729720c8db</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pinhole camera model</td>\n",
       "      <td>The pinhole camera model yields the distance e...</td>\n",
       "      <td>At test time , we compute the ratio between th...</td>\n",
       "      <td>It follows that with principal points and boun...</td>\n",
       "      <td>Projective Distance Estimation .</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>47483.0</td>\n",
       "      <td>1c0e8c3fb143eb5eb5af3026eae7257255fcf814</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overfeat - 7</td>\n",
       "      <td>We also compare WSDDN to the SPP - net [ refer...</td>\n",
       "      <td>WS - DDN S and M improves 8 and 7 points over ...</td>\n",
       "      <td>While they do not perform fine - tuning , they...</td>\n",
       "      <td>Classification Results</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>33740.0</td>\n",
       "      <td>128c727ac06fcc50f1735cb222a441eee6adcab6</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>linear state - of - the - art models</td>\n",
       "      <td>We further show that previous linear state - o...</td>\n",
       "      <td>As well as being fully expressive , TuckER ’s ...</td>\n",
       "      <td>Future work might include exploring various me...</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>43136.0</td>\n",
       "      <td>19839ffab4c30db1556d7fd9275d1344a6e3fa46</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2 dropout</td>\n",
       "      <td>We apply 0.5 dropout to the word embeddings an...</td>\n",
       "      <td>Training Details During training , we use the ...</td>\n",
       "      <td>In the LSTMs , we employ variational dropout m...</td>\n",
       "      <td>Hyperparameters</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>63118.0</td>\n",
       "      <td>27c761258329eddb90b64d52679ff190cb4527b5</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recurrent convolution networks</td>\n",
       "      <td>This research demonstrates two modified and im...</td>\n",
       "      <td>Thus , it is important to design efficient DCN...</td>\n",
       "      <td>To accomplish our goals , the proposed models ...</td>\n",
       "      <td>I. INTRODUCTION</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>38702.0</td>\n",
       "      <td>15e07c1344e97e46ade2ee0a57017371fa05fe12</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Margin - based scoring</td>\n",
       "      <td>subsection : Margin - based scoring</td>\n",
       "      <td>We next describe our scoring method inspired b...</td>\n",
       "      <td>In order to account for the relative scale of ...</td>\n",
       "      <td>Margin - based scoring</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>96752.0</td>\n",
       "      <td>3febb2bed8865945e7fddc99efd791887bb7e14f</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top LSTM layer</td>\n",
       "      <td>More specifically , we learn a linear combinat...</td>\n",
       "      <td>Unlike previous approaches for learning contex...</td>\n",
       "      <td>Combining the internal states in this manner a...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>103164.0</td>\n",
       "      <td>43428880d75b3a14257c3ee9bda054e61eb869c0</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nvidia M40 GPU</td>\n",
       "      <td>[ reference ] . All models are implemented in ...</td>\n",
       "      <td>Besides dropout on the embeddings and the deco...</td>\n",
       "      <td>We train on up to eight GPUs synchronously by ...</td>\n",
       "      <td>Model Parameters and Optimization</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>37417.0</td>\n",
       "      <td>15212fa4d30863ea1f9bd9591eee03848278242d</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JaTeCS framework</td>\n",
       "      <td>A drawback of JaDCI is thus that , for the res...</td>\n",
       "      <td>JaTeCS is a complex package , since it makes a...</td>\n",
       "      <td>In this paper we present PyDCI , a new impleme...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>4396.0</td>\n",
       "      <td>027f9695189355d18ec6be8e48f3d23ea25db35d</td>\n",
       "      <td>Method</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GumbelSoftmax</td>\n",
       "      <td>GumbelSoftmax is known to have an advantage ov...</td>\n",
       "      <td>Since it approximates one - hot vectors sample...</td>\n",
       "      <td>[ reference ] .</td>\n",
       "      <td>Gumbel - Softmax</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>105366.0</td>\n",
       "      <td>4508f81033c9a7cec785ce4d16f1193920c1b341</td>\n",
       "      <td>Method</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neural sequence models</td>\n",
       "      <td>Table [ reference ] lists recent results of va...</td>\n",
       "      <td>At each step we sample a batch of sequences of...</td>\n",
       "      <td>All the results except for the ByteNet result ...</td>\n",
       "      <td>Character Prediction</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                    doc_id relation  used  \\\n",
       "0      30875.0  10203151008a20b32ce089f7f9d580005c2426cf   Method   0.0   \n",
       "1      97801.0  4087ebc37a1650dbb5d8205af0850bee74f3784b   Method   1.0   \n",
       "2      54406.0  220a0b46840a2a1421c62d3d343397ab087a3f17   Method   0.0   \n",
       "3     103733.0  435259c5f3cffd75ef837a8e638cc8f6244e25c4   Method   0.0   \n",
       "4      17186.0  0a053f55804eee01f3c8b4138a1d3364d5bc45ac   Method   0.0   \n",
       "5      38388.0  15cc54ed7b1582b2efd71bedf28b23634d82991b   Method   1.0   \n",
       "6      27104.0  0ee850dd6640a96531ac5ad21da5438db04d8b3c   Method   1.0   \n",
       "7      25448.0  0d5fa5be4bfe085de8f88dbee1c3b2a6e5ab9ee2   Method   1.0   \n",
       "8      12675.0  071b16f25117fb6133480c6259227d54fc2a5ea0   Method   0.0   \n",
       "9      72738.0  2e10643c3759f97b673ff8c297778c0b6c20032b   Method   1.0   \n",
       "10    107712.0  46018a894d533813d67322827ca51f78aed6d59e   Method   1.0   \n",
       "11      4393.0  027f9695189355d18ec6be8e48f3d23ea25db35d   Method   0.0   \n",
       "12     13557.0  07c4fc48ad7b7d1a417b0bb72d0ae2d4efc5aa83   Method   0.0   \n",
       "13      5922.0  03184ac97ebf0724c45a29ab49f2a8ce59ac2de3   Method   1.0   \n",
       "14     34427.0  12f008bea798a05ebfa2864ec026999cb375bcd9   Method   1.0   \n",
       "15      4893.0  02a5b7a41ffa8518eb3b7cae9914a2bd2bbc886b   Method   1.0   \n",
       "16     61151.0  25c108a56e4cb757b62911639a40e9caf07f1b4f   Method   1.0   \n",
       "17     27028.0  0ecd4fdce541317b38124967b5c2a259d8f43c91   Method   1.0   \n",
       "18     79855.0  33a8d0a35390fde736744d4a0dd20dff7961c777   Method   1.0   \n",
       "19     52443.0  207e0ac5301a3c79af862951b70632ed650f74f7   Method   1.0   \n",
       "20     46567.0  1bc072002d97808340b312b69427baf2dc9fcb8e   Method   1.0   \n",
       "21    102438.0  42f20d37f4eba56284a941d5f9f58609ee650de0   Method   0.0   \n",
       "22     33378.0  1109b663453e78a59e4f66446d71720ac58cec25   Method   1.0   \n",
       "23     98917.0  40eb1e54cb5382dfd3b7efd16dc7df826262ea52   Method   1.0   \n",
       "24    104535.0  4402c6c8445f17f4161e0f64573b7e28df1ca180   Method   1.0   \n",
       "25     17068.0  0a053f55804eee01f3c8b4138a1d3364d5bc45ac   Method   1.0   \n",
       "26     72024.0  2dad7e558a1e2982d0d42042021f4cde4af04abf   Method   1.0   \n",
       "27     72901.0  2e4c06dd00c4c09ad5ac6be883cc66c19d88ea79   Method   1.0   \n",
       "28     29656.0  0fbd17a4f791e04bbf8f240f7c48c178900e30a6   Method   1.0   \n",
       "29      7767.0  051b3763c2ad4e4271db712b0e9a4cfe298d05db   Method   1.0   \n",
       "30     18807.0  0a3a003457f5d7758a42a0e4b7278b39a86ed0bd   Method   1.0   \n",
       "31     93702.0  3d734edc41c13fb4da2c3709e8255b004d083962   Method   1.0   \n",
       "32     99486.0  41232a69c0f8d4b993e6c6e00b16c223442c962f   Method   1.0   \n",
       "33    103516.0  434bf475addfb580707208618f99c8be0c55cf95   Method   0.0   \n",
       "34     71595.0  2d876ed1dd2c58058d7197b734a8e4d349b8f231   Method   0.0   \n",
       "35     86649.0  36c3972569a6949ecca90bfa6f8e99883e092845   Method   1.0   \n",
       "36     53325.0  20cc4bfdb648fd7947c71252589fc867d4d16933   Method   1.0   \n",
       "37     35823.0  143a3186c368544ded00a444be33153420baa254   Method   1.0   \n",
       "38     28073.0  0f0cab9235bbf185acdd4f9713fd111ca50effca   Method   0.0   \n",
       "39     15174.0  0899bb0f3d5425c88b358638bb8556729720c8db   Method   1.0   \n",
       "40     47483.0  1c0e8c3fb143eb5eb5af3026eae7257255fcf814   Method   1.0   \n",
       "41     33740.0  128c727ac06fcc50f1735cb222a441eee6adcab6   Method   0.0   \n",
       "42     43136.0  19839ffab4c30db1556d7fd9275d1344a6e3fa46   Method   1.0   \n",
       "43     63118.0  27c761258329eddb90b64d52679ff190cb4527b5   Method   1.0   \n",
       "44     38702.0  15e07c1344e97e46ade2ee0a57017371fa05fe12   Method   1.0   \n",
       "45     96752.0  3febb2bed8865945e7fddc99efd791887bb7e14f   Method   1.0   \n",
       "46    103164.0  43428880d75b3a14257c3ee9bda054e61eb869c0   Method   1.0   \n",
       "47     37417.0  15212fa4d30863ea1f9bd9591eee03848278242d   Method   0.0   \n",
       "48      4396.0  027f9695189355d18ec6be8e48f3d23ea25db35d   Method   0.0   \n",
       "49    105366.0  4508f81033c9a7cec785ce4d16f1193920c1b341   Method   1.0   \n",
       "\n",
       "    used_Felix Anmerkung                                                ner  \\\n",
       "0          0.0       NaN                    convolutional layer activations   \n",
       "1          1.0       NaN                              weight initialization   \n",
       "2          0.0       NaN                          Spatio - temporal filters   \n",
       "3          0.0       NaN                          sliding - window strategy   \n",
       "4          0.0       NaN                                          Neural LP   \n",
       "5          1.0       NaN                                      MMD - rep - b   \n",
       "6          1.0       NaN                         deep neural ranking models   \n",
       "7          1.0       NaN                       gradual feature fusion steps   \n",
       "8          0.0       NaN             long short - term memory ( LSTM ) unit   \n",
       "9          1.0       NaN                    distributed word representation   \n",
       "10         1.0       NaN                                        basic model   \n",
       "11         0.0       NaN                              Concrete distribution   \n",
       "12         0.0       NaN                            convolution window size   \n",
       "13         1.0       NaN                          Attribute representations   \n",
       "14         1.0         ?                                          AS Reader   \n",
       "15         1.0       NaN                                 Min - max strategy   \n",
       "16         1.0       NaN                                    shallow version   \n",
       "17         0.0       NaN                                          Markovian   \n",
       "18         1.0       NaN                                  dropout technique   \n",
       "19         1.0       NaN                          deep learning based model   \n",
       "20         1.0       NaN                     feature transformation methods   \n",
       "21         0.0       NaN                                     assumed kernel   \n",
       "22         1.0       NaN                              localization approach   \n",
       "23         1.0       NaN                             box estimation network   \n",
       "24         1.0       NaN                                      relu function   \n",
       "25         1.0       NaN                           embedding - based models   \n",
       "26         0.0       NaN                                     dilated models   \n",
       "27         1.0       NaN                                augmented MBCE loss   \n",
       "28         1.0       NaN                                        smooth loss   \n",
       "29         1.0       NaN                                     f - warp layer   \n",
       "30         1.0       NaN                              meta - batch strategy   \n",
       "31         1.0       NaN  MULTI - SCALE INFORMATION LEARNING NETWORK STR...   \n",
       "32         1.0       NaN                           sequence - to - sequence   \n",
       "33         0.0       NaN                      sparse feature representation   \n",
       "34         0.0       NaN                    cuDNN library ’s RNN primitives   \n",
       "35         1.0       NaN                                   Detectron models   \n",
       "36         1.0       NaN                                                 PC   \n",
       "37         1.0       NaN                               pretraining baseline   \n",
       "38         0.0       NaN                                       LogEig layer   \n",
       "39         1.0       NaN                               pinhole camera model   \n",
       "40         1.0       NaN                                       Overfeat - 7   \n",
       "41         0.0         ?               linear state - of - the - art models   \n",
       "42         1.0       NaN                                        0.2 dropout   \n",
       "43         1.0       NaN                     recurrent convolution networks   \n",
       "44         1.0       NaN                             Margin - based scoring   \n",
       "45         1.0       NaN                                     top LSTM layer   \n",
       "46         1.0       NaN                                     Nvidia M40 GPU   \n",
       "47         1.0       NaN                                   JaTeCS framework   \n",
       "48         0.0       NaN                                      GumbelSoftmax   \n",
       "49         1.0       NaN                             neural sequence models   \n",
       "\n",
       "                                             sentence  \\\n",
       "0   In particular for image retrieval , Babenko et...   \n",
       "1   A poor weight initialization may take longer t...   \n",
       "2                         Spatio - temporal filters .   \n",
       "3   A naive approach follows a sliding - window st...   \n",
       "4   IRN and Neural LP explore multi - step relatio...   \n",
       "5   [ reference ] shows that : When PICO was used ...   \n",
       "6   In particular , we use classic unsupervised IR...   \n",
       "7   With proposed gradual feature fusion steps and...   \n",
       "8   This gated unit is similar to a long short - t...   \n",
       "9   Comparing with traditional models , this sugge...   \n",
       "10  The segmentation results on two subjects from ...   \n",
       "11  Gumbel - Softmax ( Jang , Gu , and Poole 2017 ...   \n",
       "12  subsection : Filter dilation and convolution w...   \n",
       "13  Attribute representations are defined as a vec...   \n",
       "14  Lastly , on CBT - CN the GA Reader with the qe...   \n",
       "15  To initialise SiamMask , we extract the axis -...   \n",
       "16  The structure of our model is a shallow versio...   \n",
       "17  The RAM is therefore a relatively compact repr...   \n",
       "18  In between intermediate layers , we use batch ...   \n",
       "19  In addition , deep learning based model is als...   \n",
       "20  To get our DNNs efficiently work , we propose ...   \n",
       "21  On the other hand , when the assumed kernel is...   \n",
       "22  Our localization approach won the 2013 ILSVRC ...   \n",
       "23  The center residual predicted by the box estim...   \n",
       "24  Compared with the sigmoidal family , relu func...   \n",
       "25  We compare against RL - based methods , embedd...   \n",
       "26  Also , the dilated models outperform their reg...   \n",
       "27  In this work , we enforce both inputs to be in...   \n",
       "28  We used Focal loss with and smooth loss for cl...   \n",
       "29  Unlike Spatial Transformer , f - warp layer is...   \n",
       "30  Using our HT meta - batch strategy , hard task...   \n",
       "31  section : PROPOSED MULTI - SCALE INFORMATION L...   \n",
       "32  The dual - attention sequence - to - sequence ...   \n",
       "33  This helps creating a sparse feature represent...   \n",
       "34  It is also important to note that the cuDNN li...   \n",
       "35  Second , we choose models trained with differe...   \n",
       "36  To qualitatively study the improvement in loca...   \n",
       "37  The pretraining baseline in the main text trai...   \n",
       "38  The final LogEig layer endows elements in Riem...   \n",
       "39  The pinhole camera model yields the distance e...   \n",
       "40  We also compare WSDDN to the SPP - net [ refer...   \n",
       "41  We further show that previous linear state - o...   \n",
       "42  We apply 0.5 dropout to the word embeddings an...   \n",
       "43  This research demonstrates two modified and im...   \n",
       "44                subsection : Margin - based scoring   \n",
       "45  More specifically , we learn a linear combinat...   \n",
       "46  [ reference ] . All models are implemented in ...   \n",
       "47  A drawback of JaDCI is thus that , for the res...   \n",
       "48  GumbelSoftmax is known to have an advantage ov...   \n",
       "49  Table [ reference ] lists recent results of va...   \n",
       "\n",
       "                                         pre_sentence  \\\n",
       "0   Using CNN layer activations as off - the - she...   \n",
       "1   Optimal parameter initialization remains a cru...   \n",
       "2   Of course spatial pyramids are widely used in ...   \n",
       "3   Originally designed for image recognition and ...   \n",
       "4   Hence , recent works have proposed approaches ...   \n",
       "5                                               Fig .   \n",
       "6   To overcome this issue , in this paper , we pr...   \n",
       "7   [ reference ] and [ reference ] show the visua...   \n",
       "8   The gated hidden unit is an alternative to the...   \n",
       "9   One of the most obvious facts one could observ...   \n",
       "10  However , we can study the impact these featur...   \n",
       "11                                                NaN   \n",
       "12  In particular , in our experiments we always a...   \n",
       "13                Discrete vs Continuous Attributes .   \n",
       "14  For CBT - NE , GA Reader with the qe - comm fe...   \n",
       "15  For each measure C ∈ { J , F } , three statist...   \n",
       "16  All faces are labelled with bounding boxes and...   \n",
       "17  The Atari 2600 has only bits of random access ...   \n",
       "18  Output of layer is then passed to two fully co...   \n",
       "19  Note that XQDA can be considered as hybrid bet...   \n",
       "20  To tackle the issue , we propose two novel mod...   \n",
       "21  Most of SISR methods actually favor for such c...   \n",
       "22  The scheme we propose involves substantial mod...   \n",
       "23  We take a “ residual ” approach for box center...   \n",
       "24                                              x ) .   \n",
       "25  We use HITS@1 , 3 and mean reciprocal rank ( M...   \n",
       "26  To the best of our knowledge , the dilated GRU...   \n",
       "27  The motivation behind this design is to mainta...   \n",
       "28  We optimized subnet with Adam starting from le...   \n",
       "29  Our network uses the proposed f - warp layer t...   \n",
       "30  The size of meta - batch is set to ( tasks ) d...   \n",
       "31  Furthermore , the output of the dilated convol...   \n",
       "32  To avoid generating fake facts in a summary , ...   \n",
       "33  When initializing the weights uniformly , half...   \n",
       "34  Note that the softmax , over a vocabulary size...   \n",
       "35  As can be seen from Fig [ reference ] , the pe...   \n",
       "36             Change in Class - Activation Mapping :   \n",
       "37                                                NaN   \n",
       "38  As discussed earlier , SPD matrices lie on Rie...   \n",
       "39  At test time , we compute the ratio between th...   \n",
       "40  WS - DDN S and M improves 8 and 7 points over ...   \n",
       "41  As well as being fully expressive , TuckER ’s ...   \n",
       "42  Training Details During training , we use the ...   \n",
       "43  Thus , it is important to design efficient DCN...   \n",
       "44  We next describe our scoring method inspired b...   \n",
       "45  Unlike previous approaches for learning contex...   \n",
       "46  Besides dropout on the embeddings and the deco...   \n",
       "47  JaTeCS is a complex package , since it makes a...   \n",
       "48  Since it approximates one - hot vectors sample...   \n",
       "49  At each step we sample a batch of sequences of...   \n",
       "\n",
       "                                        post_sentence  \\\n",
       "0   Generalization to other tasks is attained by C...   \n",
       "1   Here , we propose a method of weight re - init...   \n",
       "2   Burt and Adelson lay out the theory of spatio ...   \n",
       "3   As explained before , this technique presents ...   \n",
       "4   Compared to RL - based approaches , it is hard...   \n",
       "5   For hinge and MMD - rbf , higher may result in...   \n",
       "6   Weak supervision here refers to a learning app...   \n",
       "7   Intriguingly , output of the ‘ sub4 ’ branch c...   \n",
       "8   This is made possible by having computation pa...   \n",
       "9   However , our experiments does not speak for a...   \n",
       "10  As shown in the figure , the two - phase train...   \n",
       "11  Since it approximates one - hot vectors sample...   \n",
       "12  Filter dilation , as introduced in , is a tech...   \n",
       "13  These vectors ( 85 - dim for AWA , 312 - dim f...   \n",
       "14  For each of the 4 datasets on which GA achieve...   \n",
       "15  Similarly to most VOS methods , in case of mul...   \n",
       "16  We use this model in scale - forecast network ...   \n",
       "17  The purpose of our RAM - based agent is to inv...   \n",
       "18  We set depending upon the dataset size ( towar...   \n",
       "19  For fair comparison , whenever possible ( i.e....   \n",
       "20               denoising auto - encoders ( DAEs ) .   \n",
       "21                                                NaN   \n",
       "22  The detection model was among the top performe...   \n",
       "23                                  [ reference ] ) .   \n",
       "24  Figure 5 compares these activation functions o...   \n",
       "25  For all the baseline methods , we used the imp...   \n",
       "26                                                NaN   \n",
       "27  At inference time , we use the reconstructed o...   \n",
       "28  We obtained final proposals using NMS with a t...   \n",
       "29  While transformation in FlowNet2 and SPyNet is...   \n",
       "30  The number of hard task is selected for differ...   \n",
       "31  The configuration of our proposed single image...   \n",
       "32  Experiments on the Gigaword benchmark dataset ...   \n",
       "33  Another positive aspect is the relatively chea...   \n",
       "34  That is , running an LSTM that uses a state - ...   \n",
       "35  As can be seen , this ensembling strategy is m...   \n",
       "36  As shown in Figure 3 , PC models provide tight...   \n",
       "37  To evaluate the model , as with MAML , we fine...   \n",
       "38  If be input matrix , be output matrix , the Lo...   \n",
       "39  It follows that with principal points and boun...   \n",
       "40  While they do not perform fine - tuning , they...   \n",
       "41  Future work might include exploring various me...   \n",
       "42  In the LSTMs , we employ variational dropout m...   \n",
       "43  To accomplish our goals , the proposed models ...   \n",
       "44  In order to account for the relative scale of ...   \n",
       "45  Combining the internal states in this manner a...   \n",
       "46  We train on up to eight GPUs synchronously by ...   \n",
       "47  In this paper we present PyDCI , a new impleme...   \n",
       "48                                    [ reference ] .   \n",
       "49  All the results except for the ByteNet result ...   \n",
       "\n",
       "                                         section_name  section_index  \n",
       "0                                        Introduction            1.0  \n",
       "1                                            Abstract            1.0  \n",
       "2                                        Related Work            2.0  \n",
       "3                                             Methods            4.0  \n",
       "4                           Knowledge Base Completion           15.0  \n",
       "5                                         Experiments           37.0  \n",
       "6                                        Introduction            1.0  \n",
       "7                                  Visual Improvement           24.0  \n",
       "8                            Recurrent Neural Network           23.0  \n",
       "9                                          Discussion           12.0  \n",
       "10                        The TwoPathCNN architecture           14.0  \n",
       "11                                   Gumbel - Softmax            6.0  \n",
       "12        Filter dilation and convolution window size            5.0  \n",
       "13                               Experimental Results           13.0  \n",
       "14                             Performance Comparison           11.0  \n",
       "15               Evaluation for semi - supervised VOS           12.0  \n",
       "16                   Setup and Implementation Details            9.0  \n",
       "17                     RAM - based Feature Generation           42.0  \n",
       "18                             Experiment and Results           12.0  \n",
       "19                  Fully Supervised Learning Results           12.0  \n",
       "20  Deep Learning over Multi - field Categorical Data            0.0  \n",
       "21                                      Blur kernel .            5.0  \n",
       "22                                         Discussion           15.0  \n",
       "23                  Amodal 3D Box Estimation PointNet           12.0  \n",
       "24                              1 ) Embedding Layer :           14.0  \n",
       "25                          Knowledge Base Completion           10.0  \n",
       "26                                  Language modeling           17.0  \n",
       "27                                    Link Prediction            3.0  \n",
       "28                          Person Detection Subnet :           15.0  \n",
       "29                                       Related Work            2.0  \n",
       "30                             Implementation details           17.0  \n",
       "31  PROPOSED MULTI - SCALE INFORMATION LEARNING NE...            3.0  \n",
       "32  Faithful to the Original : Fact Aware Neural A...            0.0  \n",
       "33                              Rectified Linear Unit            6.0  \n",
       "34                                  Language Modeling            6.0  \n",
       "35                                   Model Ensembling            8.0  \n",
       "36                Improvement in Localization Ability           15.0  \n",
       "37                       C.1 . Multi - task baselines           23.0  \n",
       "38                    Log Eigenvalue Layer ( LogEig )           13.0  \n",
       "39                   Projective Distance Estimation .           20.0  \n",
       "40                             Classification Results           13.0  \n",
       "41                                         Conclusion           19.0  \n",
       "42                                    Hyperparameters           16.0  \n",
       "43                                    I. INTRODUCTION            2.0  \n",
       "44                             Margin - based scoring            5.0  \n",
       "45                                       Introduction            1.0  \n",
       "46                  Model Parameters and Optimization           14.0  \n",
       "47                                       Introduction            1.0  \n",
       "48                                   Gumbel - Softmax            6.0  \n",
       "49                               Character Prediction           14.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>used_alex</th>\n",
       "      <th>used_felix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   used_alex  used_felix\n",
       "0        0.0         0.0\n",
       "1        1.0         1.0\n",
       "2        0.0         0.0\n",
       "3        0.0         0.0\n",
       "4        0.0         0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_annotation = df_1[['used_1', 'used_2']][0:50]\n",
    "df_1_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>used_alex</th>\n",
       "      <th>used_felix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   used_alex  used_felix\n",
       "0        0.0         0.0\n",
       "1        1.0         1.0\n",
       "2        1.0         1.0\n",
       "3        0.0         0.0\n",
       "4        1.0         1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_annotation = df_2[['used_1', 'used_2']][0:50]\n",
    "df_2_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>used_alex</th>\n",
       "      <th>used_felix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   used_alex  used_felix\n",
       "0        0.0         0.0\n",
       "1        1.0         1.0\n",
       "2        0.0         0.0\n",
       "3        0.0         0.0\n",
       "4        0.0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation = df_1_annotation.append(df_2_annotation)\n",
    "annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577235772357723"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.cohen_kappa_score(annotation['used_1'], annotation['used_2'])\n",
    "# kappa > 0.8: perfect :)\n",
    "#see https://www.cs.brandeis.edu/~cs140b/CS140b_slides/CS140_Lect_7_InterAnnotatorAgreement.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}