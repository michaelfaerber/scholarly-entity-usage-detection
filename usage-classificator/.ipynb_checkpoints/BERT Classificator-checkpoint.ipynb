{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the annotated data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>used</th>\n",
       "      <th>ner</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pre_sentence</th>\n",
       "      <th>post_sentence</th>\n",
       "      <th>section_name</th>\n",
       "      <th>section_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30875</td>\n",
       "      <td>10203151008a20b32ce089f7f9d580005c2426cf</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>convolutional layer activations</td>\n",
       "      <td>In particular for image retrieval , Babenko et...</td>\n",
       "      <td>Using CNN layer activations as off - the - she...</td>\n",
       "      <td>Generalization to other tasks is attained by C...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97801</td>\n",
       "      <td>4087ebc37a1650dbb5d8205af0850bee74f3784b</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>weight initialization</td>\n",
       "      <td>A poor weight initialization may take longer t...</td>\n",
       "      <td>Optimal parameter initialization remains a cru...</td>\n",
       "      <td>Here , we propose a method of weight re - init...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54406</td>\n",
       "      <td>220a0b46840a2a1421c62d3d343397ab087a3f17</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>Spatio - temporal filters</td>\n",
       "      <td>Spatio - temporal filters .</td>\n",
       "      <td>Of course spatial pyramids are widely used in ...</td>\n",
       "      <td>Burt and Adelson lay out the theory of spatio ...</td>\n",
       "      <td>Related Work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103733</td>\n",
       "      <td>435259c5f3cffd75ef837a8e638cc8f6244e25c4</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>sliding - window strategy</td>\n",
       "      <td>A naive approach follows a sliding - window st...</td>\n",
       "      <td>Originally designed for image recognition and ...</td>\n",
       "      <td>As explained before , this technique presents ...</td>\n",
       "      <td>Methods</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17186</td>\n",
       "      <td>0a053f55804eee01f3c8b4138a1d3364d5bc45ac</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural LP</td>\n",
       "      <td>IRN and Neural LP explore multi - step relatio...</td>\n",
       "      <td>Hence , recent works have proposed approaches ...</td>\n",
       "      <td>Compared to RL - based approaches , it is hard...</td>\n",
       "      <td>Knowledge Base Completion</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>82657</td>\n",
       "      <td>357776cd7ee889af954f0dfdbaee71477c09ac18</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>probabilistic autoencoders</td>\n",
       "      <td>In this paper , we proposed to use the GAN fra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our method called the adversarial autoencoder ...</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>43474</td>\n",
       "      <td>19fd2c2c9d4eecb3cf1befa8ac845a860083e8e7</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>off - policy RL algorithm</td>\n",
       "      <td>The learner applies an off - policy RL algorit...</td>\n",
       "      <td>For each learner update , a minibatch of exper...</td>\n",
       "      <td>The gradients are communicated to the paramete...</td>\n",
       "      <td>Distributed Architecture</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>86913</td>\n",
       "      <td>3729a9a140aa13b3b26210d333fd19659fc21471</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>random strategy</td>\n",
       "      <td>We see that the scores of the semantic tasks d...</td>\n",
       "      <td>Table [ reference ] shows the results of train...</td>\n",
       "      <td>In our preliminary experiments , we have found...</td>\n",
       "      <td>Order of training</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>64621</td>\n",
       "      <td>289e91654f6da968d625481ef21f52892052d4fc</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>char - based models</td>\n",
       "      <td>We observed the following from the Table [ ref...</td>\n",
       "      <td>Table [ reference ] gives the performance of o...</td>\n",
       "      <td>That may be because in Chinese the words can o...</td>\n",
       "      <td>Performance Comparison</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23173</td>\n",
       "      <td>0ca2bd0e40a8f0a57665535ae1c31561370ad183</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>recurrent generalization of stochastic depth</td>\n",
       "      <td>The COPY operation used in our model can be re...</td>\n",
       "      <td>It is however different to our model in the se...</td>\n",
       "      <td>This results in occasional copy operations of ...</td>\n",
       "      <td>RELATED WORK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                    doc_id relation used  \\\n",
       "0         30875  10203151008a20b32ce089f7f9d580005c2426cf   Method    0   \n",
       "1         97801  4087ebc37a1650dbb5d8205af0850bee74f3784b   Method    1   \n",
       "2         54406  220a0b46840a2a1421c62d3d343397ab087a3f17   Method    0   \n",
       "3        103733  435259c5f3cffd75ef837a8e638cc8f6244e25c4   Method    0   \n",
       "4         17186  0a053f55804eee01f3c8b4138a1d3364d5bc45ac   Method    0   \n",
       "..          ...                                       ...      ...  ...   \n",
       "995       82657  357776cd7ee889af954f0dfdbaee71477c09ac18   Method    1   \n",
       "996       43474  19fd2c2c9d4eecb3cf1befa8ac845a860083e8e7   Method    1   \n",
       "997       86913  3729a9a140aa13b3b26210d333fd19659fc21471   Method    1   \n",
       "998       64621  289e91654f6da968d625481ef21f52892052d4fc   Method    1   \n",
       "999       23173  0ca2bd0e40a8f0a57665535ae1c31561370ad183   Method    0   \n",
       "\n",
       "                                              ner  \\\n",
       "0                 convolutional layer activations   \n",
       "1                           weight initialization   \n",
       "2                       Spatio - temporal filters   \n",
       "3                       sliding - window strategy   \n",
       "4                                       Neural LP   \n",
       "..                                            ...   \n",
       "995                    probabilistic autoencoders   \n",
       "996                     off - policy RL algorithm   \n",
       "997                               random strategy   \n",
       "998                           char - based models   \n",
       "999  recurrent generalization of stochastic depth   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    In particular for image retrieval , Babenko et...   \n",
       "1    A poor weight initialization may take longer t...   \n",
       "2                          Spatio - temporal filters .   \n",
       "3    A naive approach follows a sliding - window st...   \n",
       "4    IRN and Neural LP explore multi - step relatio...   \n",
       "..                                                 ...   \n",
       "995  In this paper , we proposed to use the GAN fra...   \n",
       "996  The learner applies an off - policy RL algorit...   \n",
       "997  We see that the scores of the semantic tasks d...   \n",
       "998  We observed the following from the Table [ ref...   \n",
       "999  The COPY operation used in our model can be re...   \n",
       "\n",
       "                                          pre_sentence  \\\n",
       "0    Using CNN layer activations as off - the - she...   \n",
       "1    Optimal parameter initialization remains a cru...   \n",
       "2    Of course spatial pyramids are widely used in ...   \n",
       "3    Originally designed for image recognition and ...   \n",
       "4    Hence , recent works have proposed approaches ...   \n",
       "..                                                 ...   \n",
       "995                                                NaN   \n",
       "996  For each learner update , a minibatch of exper...   \n",
       "997  Table [ reference ] shows the results of train...   \n",
       "998  Table [ reference ] gives the performance of o...   \n",
       "999  It is however different to our model in the se...   \n",
       "\n",
       "                                         post_sentence  \\\n",
       "0    Generalization to other tasks is attained by C...   \n",
       "1    Here , we propose a method of weight re - init...   \n",
       "2    Burt and Adelson lay out the theory of spatio ...   \n",
       "3    As explained before , this technique presents ...   \n",
       "4    Compared to RL - based approaches , it is hard...   \n",
       "..                                                 ...   \n",
       "995  Our method called the adversarial autoencoder ...   \n",
       "996  The gradients are communicated to the paramete...   \n",
       "997  In our preliminary experiments , we have found...   \n",
       "998  That may be because in Chinese the words can o...   \n",
       "999  This results in occasional copy operations of ...   \n",
       "\n",
       "                  section_name  section_index  \n",
       "0                 Introduction              1  \n",
       "1                     Abstract              1  \n",
       "2                 Related Work              2  \n",
       "3                      Methods              4  \n",
       "4    Knowledge Base Completion             15  \n",
       "..                         ...            ...  \n",
       "995                 Conclusion             12  \n",
       "996   Distributed Architecture              7  \n",
       "997          Order of training             33  \n",
       "998     Performance Comparison             24  \n",
       "999               RELATED WORK              3  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('annotation_data_train_out.csv', sep=\";\")\n",
    "df.drop(['used_Felix', 'Anmerkung'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>used</th>\n",
       "      <th>ner</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pre_sentence</th>\n",
       "      <th>post_sentence</th>\n",
       "      <th>section_name</th>\n",
       "      <th>section_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30875</td>\n",
       "      <td>10203151008a20b32ce089f7f9d580005c2426cf</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>convolutional layer activations</td>\n",
       "      <td>In particular for image retrieval , Babenko et...</td>\n",
       "      <td>Using CNN layer activations as off - the - she...</td>\n",
       "      <td>Generalization to other tasks is attained by C...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97801</td>\n",
       "      <td>4087ebc37a1650dbb5d8205af0850bee74f3784b</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>weight initialization</td>\n",
       "      <td>A poor weight initialization may take longer t...</td>\n",
       "      <td>Optimal parameter initialization remains a cru...</td>\n",
       "      <td>Here , we propose a method of weight re - init...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54406</td>\n",
       "      <td>220a0b46840a2a1421c62d3d343397ab087a3f17</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>Spatio - temporal filters</td>\n",
       "      <td>Spatio - temporal filters .</td>\n",
       "      <td>Of course spatial pyramids are widely used in ...</td>\n",
       "      <td>Burt and Adelson lay out the theory of spatio ...</td>\n",
       "      <td>Related Work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103733</td>\n",
       "      <td>435259c5f3cffd75ef837a8e638cc8f6244e25c4</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>sliding - window strategy</td>\n",
       "      <td>A naive approach follows a sliding - window st...</td>\n",
       "      <td>Originally designed for image recognition and ...</td>\n",
       "      <td>As explained before , this technique presents ...</td>\n",
       "      <td>Methods</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17186</td>\n",
       "      <td>0a053f55804eee01f3c8b4138a1d3364d5bc45ac</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural LP</td>\n",
       "      <td>IRN and Neural LP explore multi - step relatio...</td>\n",
       "      <td>Hence , recent works have proposed approaches ...</td>\n",
       "      <td>Compared to RL - based approaches , it is hard...</td>\n",
       "      <td>Knowledge Base Completion</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>82657</td>\n",
       "      <td>357776cd7ee889af954f0dfdbaee71477c09ac18</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>probabilistic autoencoders</td>\n",
       "      <td>In this paper , we proposed to use the GAN fra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our method called the adversarial autoencoder ...</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>43474</td>\n",
       "      <td>19fd2c2c9d4eecb3cf1befa8ac845a860083e8e7</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>off - policy RL algorithm</td>\n",
       "      <td>The learner applies an off - policy RL algorit...</td>\n",
       "      <td>For each learner update , a minibatch of exper...</td>\n",
       "      <td>The gradients are communicated to the paramete...</td>\n",
       "      <td>Distributed Architecture</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>86913</td>\n",
       "      <td>3729a9a140aa13b3b26210d333fd19659fc21471</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>random strategy</td>\n",
       "      <td>We see that the scores of the semantic tasks d...</td>\n",
       "      <td>Table [ reference ] shows the results of train...</td>\n",
       "      <td>In our preliminary experiments , we have found...</td>\n",
       "      <td>Order of training</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>64621</td>\n",
       "      <td>289e91654f6da968d625481ef21f52892052d4fc</td>\n",
       "      <td>Method</td>\n",
       "      <td>1</td>\n",
       "      <td>char - based models</td>\n",
       "      <td>We observed the following from the Table [ ref...</td>\n",
       "      <td>Table [ reference ] gives the performance of o...</td>\n",
       "      <td>That may be because in Chinese the words can o...</td>\n",
       "      <td>Performance Comparison</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23173</td>\n",
       "      <td>0ca2bd0e40a8f0a57665535ae1c31561370ad183</td>\n",
       "      <td>Method</td>\n",
       "      <td>0</td>\n",
       "      <td>recurrent generalization of stochastic depth</td>\n",
       "      <td>The COPY operation used in our model can be re...</td>\n",
       "      <td>It is however different to our model in the se...</td>\n",
       "      <td>This results in occasional copy operations of ...</td>\n",
       "      <td>RELATED WORK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                    doc_id relation used  \\\n",
       "0         30875  10203151008a20b32ce089f7f9d580005c2426cf   Method    0   \n",
       "1         97801  4087ebc37a1650dbb5d8205af0850bee74f3784b   Method    1   \n",
       "2         54406  220a0b46840a2a1421c62d3d343397ab087a3f17   Method    0   \n",
       "3        103733  435259c5f3cffd75ef837a8e638cc8f6244e25c4   Method    0   \n",
       "4         17186  0a053f55804eee01f3c8b4138a1d3364d5bc45ac   Method    0   \n",
       "..          ...                                       ...      ...  ...   \n",
       "995       82657  357776cd7ee889af954f0dfdbaee71477c09ac18   Method    1   \n",
       "996       43474  19fd2c2c9d4eecb3cf1befa8ac845a860083e8e7   Method    1   \n",
       "997       86913  3729a9a140aa13b3b26210d333fd19659fc21471   Method    1   \n",
       "998       64621  289e91654f6da968d625481ef21f52892052d4fc   Method    1   \n",
       "999       23173  0ca2bd0e40a8f0a57665535ae1c31561370ad183   Method    0   \n",
       "\n",
       "                                              ner  \\\n",
       "0                 convolutional layer activations   \n",
       "1                           weight initialization   \n",
       "2                       Spatio - temporal filters   \n",
       "3                       sliding - window strategy   \n",
       "4                                       Neural LP   \n",
       "..                                            ...   \n",
       "995                    probabilistic autoencoders   \n",
       "996                     off - policy RL algorithm   \n",
       "997                               random strategy   \n",
       "998                           char - based models   \n",
       "999  recurrent generalization of stochastic depth   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    In particular for image retrieval , Babenko et...   \n",
       "1    A poor weight initialization may take longer t...   \n",
       "2                          Spatio - temporal filters .   \n",
       "3    A naive approach follows a sliding - window st...   \n",
       "4    IRN and Neural LP explore multi - step relatio...   \n",
       "..                                                 ...   \n",
       "995  In this paper , we proposed to use the GAN fra...   \n",
       "996  The learner applies an off - policy RL algorit...   \n",
       "997  We see that the scores of the semantic tasks d...   \n",
       "998  We observed the following from the Table [ ref...   \n",
       "999  The COPY operation used in our model can be re...   \n",
       "\n",
       "                                          pre_sentence  \\\n",
       "0    Using CNN layer activations as off - the - she...   \n",
       "1    Optimal parameter initialization remains a cru...   \n",
       "2    Of course spatial pyramids are widely used in ...   \n",
       "3    Originally designed for image recognition and ...   \n",
       "4    Hence , recent works have proposed approaches ...   \n",
       "..                                                 ...   \n",
       "995                                                NaN   \n",
       "996  For each learner update , a minibatch of exper...   \n",
       "997  Table [ reference ] shows the results of train...   \n",
       "998  Table [ reference ] gives the performance of o...   \n",
       "999  It is however different to our model in the se...   \n",
       "\n",
       "                                         post_sentence  \\\n",
       "0    Generalization to other tasks is attained by C...   \n",
       "1    Here , we propose a method of weight re - init...   \n",
       "2    Burt and Adelson lay out the theory of spatio ...   \n",
       "3    As explained before , this technique presents ...   \n",
       "4    Compared to RL - based approaches , it is hard...   \n",
       "..                                                 ...   \n",
       "995  Our method called the adversarial autoencoder ...   \n",
       "996  The gradients are communicated to the paramete...   \n",
       "997  In our preliminary experiments , we have found...   \n",
       "998  That may be because in Chinese the words can o...   \n",
       "999  This results in occasional copy operations of ...   \n",
       "\n",
       "                  section_name  section_index  \n",
       "0                 Introduction              1  \n",
       "1                     Abstract              1  \n",
       "2                 Related Work              2  \n",
       "3                      Methods              4  \n",
       "4    Knowledge Base Completion             15  \n",
       "..                         ...            ...  \n",
       "995                 Conclusion             12  \n",
       "996   Distributed Architecture              7  \n",
       "997          Order of training             33  \n",
       "998     Performance Comparison             24  \n",
       "999               RELATED WORK              3  \n",
       "\n",
       "[994 rows x 10 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[(df['used'] == \"1\") | (df['used'] == \"0\")]\n",
    "print(len(filtered_df))\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_df[['ner', 'pre_sentence', 'sentence', 'post_sentence']]\n",
    "y = pd.to_numeric(filtered_df['used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner</th>\n",
       "      <th>pre_sentence</th>\n",
       "      <th>sentence</th>\n",
       "      <th>post_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convolutional layer activations</td>\n",
       "      <td>Using CNN layer activations as off - the - she...</td>\n",
       "      <td>In particular for image retrieval , Babenko et...</td>\n",
       "      <td>Generalization to other tasks is attained by C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight initialization</td>\n",
       "      <td>Optimal parameter initialization remains a cru...</td>\n",
       "      <td>A poor weight initialization may take longer t...</td>\n",
       "      <td>Here , we propose a method of weight re - init...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spatio - temporal filters</td>\n",
       "      <td>Of course spatial pyramids are widely used in ...</td>\n",
       "      <td>Spatio - temporal filters .</td>\n",
       "      <td>Burt and Adelson lay out the theory of spatio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sliding - window strategy</td>\n",
       "      <td>Originally designed for image recognition and ...</td>\n",
       "      <td>A naive approach follows a sliding - window st...</td>\n",
       "      <td>As explained before , this technique presents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural LP</td>\n",
       "      <td>Hence , recent works have proposed approaches ...</td>\n",
       "      <td>IRN and Neural LP explore multi - step relatio...</td>\n",
       "      <td>Compared to RL - based approaches , it is hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>probabilistic autoencoders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper , we proposed to use the GAN fra...</td>\n",
       "      <td>Our method called the adversarial autoencoder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>off - policy RL algorithm</td>\n",
       "      <td>For each learner update , a minibatch of exper...</td>\n",
       "      <td>The learner applies an off - policy RL algorit...</td>\n",
       "      <td>The gradients are communicated to the paramete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>random strategy</td>\n",
       "      <td>Table [ reference ] shows the results of train...</td>\n",
       "      <td>We see that the scores of the semantic tasks d...</td>\n",
       "      <td>In our preliminary experiments , we have found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>char - based models</td>\n",
       "      <td>Table [ reference ] gives the performance of o...</td>\n",
       "      <td>We observed the following from the Table [ ref...</td>\n",
       "      <td>That may be because in Chinese the words can o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>recurrent generalization of stochastic depth</td>\n",
       "      <td>It is however different to our model in the se...</td>\n",
       "      <td>The COPY operation used in our model can be re...</td>\n",
       "      <td>This results in occasional copy operations of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ner  \\\n",
       "0                 convolutional layer activations   \n",
       "1                           weight initialization   \n",
       "2                       Spatio - temporal filters   \n",
       "3                       sliding - window strategy   \n",
       "4                                       Neural LP   \n",
       "..                                            ...   \n",
       "995                    probabilistic autoencoders   \n",
       "996                     off - policy RL algorithm   \n",
       "997                               random strategy   \n",
       "998                           char - based models   \n",
       "999  recurrent generalization of stochastic depth   \n",
       "\n",
       "                                          pre_sentence  \\\n",
       "0    Using CNN layer activations as off - the - she...   \n",
       "1    Optimal parameter initialization remains a cru...   \n",
       "2    Of course spatial pyramids are widely used in ...   \n",
       "3    Originally designed for image recognition and ...   \n",
       "4    Hence , recent works have proposed approaches ...   \n",
       "..                                                 ...   \n",
       "995                                                NaN   \n",
       "996  For each learner update , a minibatch of exper...   \n",
       "997  Table [ reference ] shows the results of train...   \n",
       "998  Table [ reference ] gives the performance of o...   \n",
       "999  It is however different to our model in the se...   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    In particular for image retrieval , Babenko et...   \n",
       "1    A poor weight initialization may take longer t...   \n",
       "2                          Spatio - temporal filters .   \n",
       "3    A naive approach follows a sliding - window st...   \n",
       "4    IRN and Neural LP explore multi - step relatio...   \n",
       "..                                                 ...   \n",
       "995  In this paper , we proposed to use the GAN fra...   \n",
       "996  The learner applies an off - policy RL algorit...   \n",
       "997  We see that the scores of the semantic tasks d...   \n",
       "998  We observed the following from the Table [ ref...   \n",
       "999  The COPY operation used in our model can be re...   \n",
       "\n",
       "                                         post_sentence  \n",
       "0    Generalization to other tasks is attained by C...  \n",
       "1    Here , we propose a method of weight re - init...  \n",
       "2    Burt and Adelson lay out the theory of spatio ...  \n",
       "3    As explained before , this technique presents ...  \n",
       "4    Compared to RL - based approaches , it is hard...  \n",
       "..                                                 ...  \n",
       "995  Our method called the adversarial autoencoder ...  \n",
       "996  The gradients are communicated to the paramete...  \n",
       "997  In our preliminary experiments , we have found...  \n",
       "998  That may be because in Chinese the words can o...  \n",
       "999  This results in occasional copy operations of ...  \n",
       "\n",
       "[994 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(*X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load SciBERT transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "# Load pre-trained model (weights)\n",
    "config = AutoConfig.from_pretrained(\"allenai/scibert_scivocab_uncased\", output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolutional layer activations In particular for image retrieval , Babenko et al . and Gong et al . concurrently propose the use of Fully Connected ( FC ) layer activations as descriptors , while convolutional layer activations are later shown to have superior performance .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "X_embeddings = []\n",
    "for entry in X_numpy:\n",
    "    inputs = tokenizer.encode_plus(\n",
    "            entry[2],\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            pad_to_max_length=False,\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "    )\n",
    "    \n",
    "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
    "    input_ids = inputs['input_ids'][0].cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        # Word embeddings for every *token*\n",
    "        result = model(**inputs)\n",
    "        # Sequence of hidden-states at the output of the last layer of the model.\n",
    "        predictions = result[0].cpu().numpy()\n",
    "\n",
    "        # We need to find the corresponding embedding sequence for our token\n",
    "        ids = np.array(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(entry[0])))\n",
    "        found = False\n",
    "        for i in range(0, len(input_ids) - len(ids) + 1):\n",
    "            if (input_ids[i:i + len(ids)] == ids).all():\n",
    "                # Use the average for all tokens of the entity\n",
    "                # https://github.com/huggingface/transformers/issues/1950#issuecomment-558697929\n",
    "                X_embeddings.append(np.mean(predictions[0][i:i + len(ids)], axis=0))\n",
    "                found = True\n",
    "                break  # only add one embedding per entity\n",
    "        if not found:\n",
    "            print(\"Error, did not find\", entry[0])\n",
    "                \n",
    "len(X_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_embeddings) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5882352941176471, 0.5263157894736842, 0.5555555555555555, None)\n",
      "(0.6, 0.5842105263157895, 0.5920000000000001, None)\n",
      "(0.6842105263157895, 0.5473684210526316, 0.6081871345029239, None)\n",
      "(0.609375, 0.6157894736842106, 0.612565445026178, None)\n",
      "(0.6032608695652174, 0.5842105263157895, 0.5935828877005347, None)\n",
      "(0.5786516853932584, 0.5421052631578948, 0.5597826086956521, None)\n",
      "(0.6292134831460674, 0.8842105263157894, 0.7352297592997812, None)\n",
      "(0.6538461538461539, 0.8052631578947368, 0.7216981132075472, None)\n",
      "(0.6987951807228916, 0.6105263157894737, 0.651685393258427, None)\n",
      "(0.7548387096774194, 0.6157894736842106, 0.6782608695652175, None)\n",
      "(0.6914285714285714, 0.6368421052631579, 0.663013698630137, None)\n",
      "(0.711764705882353, 0.6368421052631579, 0.6722222222222222, None)\n",
      "(0.7951807228915663, 0.3473684210526316, 0.4835164835164836, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [KNeighborsClassifier(3),\n",
    "               KNeighborsClassifier(5),\n",
    "               KNeighborsClassifier(10),\n",
    "               DecisionTreeClassifier(max_depth=5),\n",
    "               DecisionTreeClassifier(max_depth=10),\n",
    "               DecisionTreeClassifier(max_depth=20),\n",
    "               RandomForestClassifier(n_estimators=1000, max_depth=3),\n",
    "               RandomForestClassifier(n_estimators=1000, max_depth=5),\n",
    "               LogisticRegression(max_iter=100000),\n",
    "               GaussianNB(),\n",
    "               MLPClassifier(hidden_layer_sizes=(100, 100, 100),\n",
    "                             max_iter=10000, activation='relu'),\n",
    "               MLPClassifier(hidden_layer_sizes=(100, 100, 100),\n",
    "                             max_iter=10000, activation='tanh'),\n",
    "               SGDClassifier(max_iter=1000, tol=1e-3)]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
